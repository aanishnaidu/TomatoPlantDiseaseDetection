{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import pickle\n",
    "import joblib\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "(12500,)\n",
      "(3632,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as geek \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "print(\"0\")\n",
    "# the array is loaded intob \n",
    "xtrain = geek.load('xtrain_rsnet.npy')\n",
    "ytrain = geek.load('ytrain_rsnet.npy')\n",
    "xtest = geek.load('xtest_rsnet.npy')\n",
    "ytest = geek.load('ytest_rsnet.npy')\n",
    "print(\"1\")\n",
    "xtrain=xtrain[:12500]\n",
    "ytrain=ytrain[:12500]\n",
    "#ytest=ytest[:5000]\n",
    "#xtest=xtest[:5000]\n",
    "\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "scaling = MinMaxScaler(feature_range=(0,1)).fit(xtrain)\n",
    "xtrain = scaling.transform(xtrain)\n",
    "xtest = scaling.transform(xtest)\n",
    "print(\"2\")\n",
    "#clf = LogisticRegression(warm_start=True,max_iter=1000)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.fit(xtrain, ytrain)\n",
    "print(\"ok1\")\n",
    "acc = clf.score(xtest, ytest)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "filename = \"logesticfinaltest3.sav\"\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9562224669603524\n",
      "0.9598017621145375\n",
      "0.962830396475771\n"
     ]
    }
   ],
   "source": [
    "filename = 'logesticfinaltest1.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(xtest, ytest)\n",
    "print(result)\n",
    "\n",
    "filename = 'logesticfinaltest2.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(xtest, ytest)\n",
    "print(result)\n",
    "\n",
    "filename = 'logesticfinaltest3.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(xtest, ytest)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-36b40f6aed9c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-36b40f6aed9c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for i in range(1:1000000000000):\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred=loaded_model.predict(xtest)\n",
    "confusion_matrix(ytest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1iter\n",
      "Accuracy: 0.8069933920704846\n",
      "2iter\n",
      "Accuracy: 0.7965308370044053\n",
      "3iter\n",
      "Accuracy: 0.8001101321585903\n",
      "4iter\n",
      "Accuracy: 0.7926762114537445\n",
      "5iter\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,29):\n",
    "    print(str(i)+\"iter\")\n",
    "    clf.fit(xtrain[500*i:((500*i)+500)], ytrain[500*i:((500*i)+500)])\n",
    "    acc = clf.score(xtest, ytest)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    #filename = \"qqq__\"+str(i)+\".sav\"\n",
    "    #pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = clf.score(xtest, ytest)\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'resnetlogestic.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
